###### ê¸°ë³¸ ì •ë³´ ì„¤ì • ë‹¨ê³„ #######
from fastapi import Request, FastAPI
import threading
import time
import queue as q
from llm import get_ai_message


###### ê¸°ëŠ¥ êµ¬í˜„ ë‹¨ê³„ #######

# ë©”ì„¸ì§€ ì „ì†¡ : ëª¨ë¸ ê°’ì„ ì¹´ì¹´ì˜¤í†¡ json í¬ë©§ ë§ê²Œ í•˜ê¸°
def textResponseFormat(bot_response):
    response = {'version': '2.0', 'template': {
    'outputs': [{"simpleText": {"text": bot_response}}], 'quickReplies': []}}
    return response

# ì‘ë‹µ ì´ˆê³¼ì‹œ ë‹µë³€
def timeover():
    response = {"version":"2.0","template":{
      "outputs":[
         {
            "simpleText":{
               "text":"ğŸ•µï¸ì œê°€ ìŠ¤í† í‚¹í•˜ë©° ê¸°ë¡í•œ ë¬¸ì„œ ì¢€ ë‘˜ëŸ¬ë³´ê² ìŠµë‹ˆë‹¤.\n ğŸ‘‡ ì¡°ê¸ˆ ìˆë‹¤ í˜¸ì¶œí•´ì£¼ì„¸ìš”."
            }
         }
      ],
      "quickReplies":[
         {
            "action":"message",
            "label":"ë¬¸ì„œ ë‹¤ ë³´ì…¨ë‚˜ìš”?ğŸ™‹",
            "messageText":"ë¬¸ì„œ ë‹¤ ë³´ì…¨ë‚˜ìš”?ğŸ™‹"
         }]}}
    return response

######## ì„œë²„ ìƒì„± #########
app = FastAPI()

@app.get("/")
async def root():
    return {"message": "kakaoTest"}

@app.post("/chat/")
async def chat(request: Request):
    kakaorequest = await request.json() # ì¹´ì¹´ì˜¤í†¡ ì„œë²„ê°€ ë³´ë‚¸ ë¦¬í€˜ìŠ¤íŠ¸ ë©”ì„¸ì§€ë¥¼ JSONìœ¼ë¡œ
    return mainChat(kakaorequest)

######## ë©”ì¸ í•¨ìˆ˜ #########

response = []

# ë©”ì¸ í•¨ìˆ˜
def mainChat(kakaorequest):

    global response
    
    start_time = time.time()   

    # ë‹µë³€ ìƒì„± í•¨ìˆ˜ ì‹¤í–‰
    request_respond = threading.Thread(target=responseModel,
                                        args=( kakaorequest, ))
    
    request_respond.start()

    # ë‹µë³€ ìƒì„± ì‹œê°„ ì²´í¬
    while (time.time() - start_time < 4 ):
        if response :
            # 4 ì´ˆ ì•ˆì— ë‹µë³€ì´ ì™„ì„±ë˜ë©´ ë°”ë¡œ ê°’ ë¦¬í„´
            temp = response[0]
            response.clear()
            return temp
        # ì•ˆì •ì ì¸ êµ¬ë™ì„ ìœ„í•œ ë”œë ˆì´ íƒ€ì„ ì„¤ì •
        time.sleep(0.01)

    # 4 ì´ˆ ë‚´ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì„ ê²½ìš°
    if not response:     
        return timeover()


# ë‹µë³€ ìƒì„± í•¨ìˆ˜
def responseModel( request ):
    global response
    if not response:
        prompt = request["userRequest"]["utterance"]
        bot_res = get_ai_message(prompt)
        response.append(textResponseFormat(bot_res))
        print(bot_res)

    